{
  "transformer_ppo_lunar": {
    "agent": [
      {
        "name": "PPO",
        "algorithm": {
          "name": "PPO",
          "action_pdtype": "default",
          "action_policy": "default",
          "explore_var_spec": null,
          "gamma": 0.99,
          "lam": 0.95,
          "clip_eps_spec": {
            "name": "no_decay",
            "start_val": 0.20,
            "end_val": 0.0,
            "start_step": 10000,
            "end_step": 300000
          },
          "entropy_coef_spec": {
            "name": "no_decay",
            "start_val": 0.01,
            "end_val": 0.01,
            "start_step": 0,
            "end_step": 0
          },
          "val_loss_coef": 1.0,
          "time_horizon": 256,
          "minibatch_size": 256,
          "training_epoch": 10
        },
        "memory": {
          "name": "OnPolicyBatchReplay",
        },
        "net": {
          "type": "TransformerNet",
          "shared": false,
          "pos_encoder": "sinusoid",
          "embed_dim": 32,
          "num_heads": 1,
          "num_hids": 256,
          "num_layers": 2,
          "dropout": 0.02,
          "init_fn": "orthogonal_",
          "batch_norm": false,
          "clip_grad_val": 0.5,
          "use_same_optim": true,
          "loss_spec": {
            "name": "MSELoss"
          },
          "actor_optim_spec": {
            "name": "Lookahead",
            "optimizer": "RAdam",
            "lr": 5e-3,
          },
          "lr_scheduler_spec": {
            "name": "MultiStepLR",
            "milestones": [50000, 100000, 15000, 200000, 25000],
            "gamma": 0.3,
          },
          "gpu": true
        }
      }
    ],
    "env": [
      {
        "name": "LunarLander-v2",
        "frame_op": "stack",
        "frame_op_len": 8,
        "normalize_state": true,
        "max_t": null,
        "max_frame": 300000,
        "num_envs": 8,
      }
    ],
    "body": {
      "product": "outer",
      "num": 1
    },
    "meta": {
      "distributed": false,
      "log_frequency": 1000,
      "eval_frequency": 1000,
      "max_session": 4,
      "max_trial": 1,
      "num_gpus": 0.25
    },
    "search": {
      "agent": [{
        "net": {
          "num_layers__grid_search": [1, 2, 3],
        }
      }]
    }
  },
  "transformer_ppo_ant": {
    "agent": [
      {
        "name": "PPO",
        "algorithm": {
          "name": "PPO",
          "action_pdtype": "default",
          "action_policy": "default",
          "explore_var_spec": null,
          "gamma": 0.99,
          "lam": 0.95,
          "clip_eps_spec": {
            "name": "no_decay",
            "start_val": 0.20,
            "end_val": 0.20,
            "start_step": 0,
            "end_step": 0
          },
          "entropy_coef_spec": {
            "name": "no_decay",
            "start_val": 0.0,
            "end_val": 0.0,
            "start_step": 0,
            "end_step": 0
          },
          "val_loss_coef": 1.0,
          "time_horizon": 1024,
          "minibatch_size": 128,
          "training_epoch": 10
        },
        "memory": {
          "name": "OnPolicyBatchReplay",
        },
        "net": {
          "type": "TransformerNet",
          "shared": false,
          "pos_encoder": "sinusoid",
          "embed_dim": 32,
          "num_heads": 4,
          "num_hids": 256,
          "num_layers": 2,
          "dropout": 0.0,
          "init_fn": "orthogonal_",
          "clip_grad_val": 0.5,
          "use_same_optim": true,
          "loss_spec": {
            "name": "MSELoss"
          },
          "actor_optim_spec": {
            "name": "Lookahead",
            "optimizer": "RAdam",
            "lr": 3e-4,
          },
          "lr_scheduler_spec": null,
          "gpu": true
        }
      }
    ],
    "env": [
      {
        "name": "RoboschoolAnt-v1",
        "frame_op": "stack",
        "frame_op_len": 8,
        "normalize_state": true,
        "num_envs": 8,
        "max_t": null,
        "max_frame": 2e6
      }
    ],
    "body": {
      "product": "outer",
      "num": 1
    },
    "meta": {
      "distributed": false,
      "log_frequency": 1000,
      "eval_frequency": 1000,
      "rigorous_eval": 0,
      "max_session": 2,
      "max_trial": 1,
      "num_gpus": 0.25
    },
    "search": {
      "agent": [{
        "algorithm": {
          "time_horizon__grid_search": [1024, 2048]
        }
      }]
    }
  },
  "transformer_ppo_atlas": {
    "agent": [
      {
        "name": "PPO",
        "algorithm": {
          "name": "PPO",
          "action_pdtype": "default",
          "action_policy": "default",
          "explore_var_spec": null,
          "gamma": 0.99,
          "lam": 0.95,
          "clip_eps_spec": {
            "name": "no_decay",
            "start_val": 0.20,
            "end_val": 0.20,
            "start_step": 0,
            "end_step": 0
          },
          "entropy_coef_spec": {
            "name": "no_decay",
            "start_val": 0.0,
            "end_val": 0.0,
            "start_step": 0,
            "end_step": 0
          },
          "val_loss_coef": 1.0,
          "time_horizon": 1024,
          "minibatch_size": 128,
          "training_epoch": 10
        },
        "memory": {
          "name": "OnPolicyBatchReplay",
        },
        "net": {
          "type": "TransformerNet",
          "shared": false,
          "pos_encoder": "sinusoid",
          "embed_dim": 32,
          "num_heads": 4,
          "num_hids": 256,
          "num_layers": 2,
          "dropout": 0.0,
          "init_fn": "orthogonal_",
          "clip_grad_val": 0.5,
          "use_same_optim": true,
          "loss_spec": {
            "name": "MSELoss"
          },
          "actor_optim_spec": {
            "name": "Lookahead",
            "optimizer": "RAdam",
            "lr": 3e-4,
          },
          "lr_scheduler_spec": null,
          "gpu": true
        }
      }
    ],
    "env": [
      {
        "name": "RoboschoolAtlasForwardWalk-v1",
        "frame_op": "stack",
        "frame_op_len": 8,
        "normalize_state": true,
        "num_envs": 8,
        "max_t": null,
        "max_frame": 2e6
      }
    ],
    "body": {
      "product": "outer",
      "num": 1
    },
    "meta": {
      "distributed": false,
      "log_frequency": 1000,
      "eval_frequency": 1000,
      "rigorous_eval": 0,
      "max_session": 2,
      "max_trial": 1,
      "num_gpus": 0.25
    }
  },
  "transformer_ppo_hopper": {
    "agent": [
      {
        "name": "PPO",
        "algorithm": {
          "name": "PPO",
          "action_pdtype": "default",
          "action_policy": "default",
          "explore_var_spec": null,
          "gamma": 0.99,
          "lam": 0.95,
          "clip_eps_spec": {
            "name": "no_decay",
            "start_val": 0.20,
            "end_val": 0.20,
            "start_step": 0,
            "end_step": 0
          },
          "entropy_coef_spec": {
            "name": "no_decay",
            "start_val": 0.01,
            "end_val": 0.01,
            "start_step": 0,
            "end_step": 0
          },
          "val_loss_coef": 1.0,
          "time_horizon": 1024,
          "minibatch_size": 128,
          "training_epoch": 10
        },
        "memory": {
          "name": "OnPolicyBatchReplay",
        },
        "net": {
          "type": "TransformerNet",
          "shared": false,
          "pos_encoder": "sinusoid",
          "embed_dim": 32,
          "num_heads": 1,
          "num_hids": 256,
          "num_layers": 2,
          "dropout": 0.02,
          "init_fn": "orthogonal_",
          "clip_grad_val": 0.5,
          "use_same_optim": true,
          "loss_spec": {
            "name": "MSELoss"
          },
          "actor_optim_spec": {
            "name": "Lookahead",
            "optimizer": "RAdam",
            "lr": 3e-4,
          },
          "lr_scheduler_spec": null,
          "gpu": true
        }
      }
    ],
    "env": [
      {
        "name": "RoboschoolHopper-v1",
        "frame_op": "stack",
        "frame_op_len": 8,
        "normalize_state": true,
        "num_envs": 8,
        "max_t": null,
        "max_frame": 2e6
      }
    ],
    "body": {
      "product": "outer",
      "num": 1
    },
    "meta": {
      "distributed": false,
      "log_frequency": 1000,
      "eval_frequency": 1000,
      "rigorous_eval": 0,
      "max_session": 2,
      "max_trial": 1,
      "num_gpus": 0.25
    },
    "search": {
      "agent": [{
        "net": {
          "embed_dim__grid_search": [16, 32],
          "num_heads__grid_search": [1, 2],
        }
      }]
    }
  },
  "transformer_ppo_halfcheetah": {
    "agent": [
      {
        "name": "PPO",
        "algorithm": {
          "name": "PPO",
          "action_pdtype": "default",
          "action_policy": "default",
          "explore_var_spec": null,
          "gamma": 0.99,
          "lam": 0.95,
          "clip_eps_spec": {
            "name": "no_decay",
            "start_val": 0.20,
            "end_val": 0.20,
            "start_step": 0,
            "end_step": 0
          },
          "entropy_coef_spec": {
            "name": "no_decay",
            "start_val": 0.0,
            "end_val": 0.0,
            "start_step": 0,
            "end_step": 0
          },
          "val_loss_coef": 1.0,
          "time_horizon": 1024,
          "minibatch_size": 128,
          "training_epoch": 10
        },
        "memory": {
          "name": "OnPolicyBatchReplay",
        },
        "net": {
          "type": "TransformerNet",
          "shared": false,
          "pos_encoder": "sinusoid",
          "embed_dim": 32,
          "num_heads": 4,
          "num_hids": 256,
          "num_layers": 2,
          "dropout": 0.0,
          "init_fn": "orthogonal_",
          "clip_grad_val": 0.5,
          "use_same_optim": true,
          "loss_spec": {
            "name": "MSELoss"
          },
          "actor_optim_spec": {
            "name": "Lookahead",
            "optimizer": "RAdam",
            "lr": 3e-4,
          },
          "lr_scheduler_spec": null,
          "gpu": true
        }
      }
    ],
    "env": [
      {
        "name": "RoboschoolHalfCheetah-v1",
        "frame_op": "stack",
        "frame_op_len": 8,
        "normalize_state": true,
        "num_envs": 8,
        "max_t": null,
        "max_frame": 2e6
      }
    ],
    "body": {
      "product": "outer",
      "num": 1
    },
    "meta": {
      "distributed": false,
      "log_frequency": 1000,
      "eval_frequency": 1000,
      "rigorous_eval": 0,
      "max_session": 2,
      "max_trial": 1,
      "num_gpus": 0.25
    },
    "search": {
      "agent": [{
        "algorithm": {
          "time_horizon__grid_search": [1024, 2048]
        }
      }]
    }
  },
  "transformer_ppo_humanoid": {
    "agent": [
      {
        "name": "PPO",
        "algorithm": {
          "name": "PPO",
          "action_pdtype": "default",
          "action_policy": "default",
          "explore_var_spec": null,
          "gamma": 0.99,
          "lam": 0.95,
          "clip_eps_spec": {
            "name": "no_decay",
            "start_val": 0.20,
            "end_val": 0.20,
            "start_step": 0,
            "end_step": 0
          },
          "entropy_coef_spec": {
            "name": "no_decay",
            "start_val": 0.0,
            "end_val": 0.0,
            "start_step": 0,
            "end_step": 0
          },
          "val_loss_coef": 1.0,
          "time_horizon": 256,
          "minibatch_size": 2048,
          "training_epoch": 15
        },
        "memory": {
          "name": "OnPolicyBatchReplay",
        },
        "net": {
          "type": "TransformerNet",
          "shared": false,
          "num_heads": 4,
          "num_hids": 256,
          "num_layers": 2,
          "dropout": 0.0,
          "init_fn": "orthogonal_",
          "clip_grad_val": 0.5,
          "use_same_optim": false,
          "loss_spec": {
            "name": "MSELoss"
          },
          "actor_optim_spec": {
            "name": "Lookahead",
            "optimizer": "RAdam",
            "lr": 3e-4,
          },
          "critic_optim_spec": {
            "name": "Lookahead",
            "optimizer": "RAdam",
            "lr": 3e-4,
          },
          "lr_scheduler_spec": null,
          "gpu": true
        }
      }
    ],
    "env": [
      {
        "name": "RoboschoolHumanoid-v1",
        "frame_op": "stack",
        "frame_op_len": 24,
        "num_envs": 32,
        "max_t": null,
        "max_frame": 5e7
      }
    ],
    "body": {
      "product": "outer",
      "num": 1
    },
    "meta": {
      "distributed": false,
      "log_frequency": 10000,
      "eval_frequency": 10000,
      "rigorous_eval": 0,
      "max_session": 1,
      "max_trial": 1
    }
  },
  "transformer_ppo_humanoidflagrun": {
    "agent": [
      {
        "name": "PPO",
        "algorithm": {
          "name": "PPO",
          "action_pdtype": "default",
          "action_policy": "default",
          "explore_var_spec": null,
          "gamma": 0.99,
          "lam": 0.95,
          "clip_eps_spec": {
            "name": "no_decay",
            "start_val": 0.20,
            "end_val": 0.20,
            "start_step": 0,
            "end_step": 0
          },
          "entropy_coef_spec": {
            "name": "no_decay",
            "start_val": 0.0,
            "end_val": 0.0,
            "start_step": 0,
            "end_step": 0
          },
          "val_loss_coef": 1.0,
          "time_horizon": 512,
          "minibatch_size": 4096,
          "training_epoch": 15
        },
        "memory": {
          "name": "OnPolicyBatchReplay",
        },
        "net": {
          "type": "TransformerNet",
          "shared": false,
          "num_heads": 4,
          "num_hids": 256,
          "num_layers": 2,
          "dropout": 0.0,
          "init_fn": "orthogonal_",
          "clip_grad_val": 0.5,
          "use_same_optim": false,
          "loss_spec": {
            "name": "MSELoss"
          },
          "actor_optim_spec": {
            "name": "Lookahead",
            "optimizer": "RAdam",
            "lr": 1e-4,
          },
          "critic_optim_spec": {
            "name": "Lookahead",
            "optimizer": "RAdam",
            "lr": 1e-4,
          },
          "lr_scheduler_spec": null,
          "gpu": true
        }
      }
    ],
    "env": [
      {
        "name": "RoboschoolHumanoidFlagrun-v1",
        "frame_op": "stack",
        "frame_op_len": 32,
        "num_envs": 32,
        "max_t": null,
        "max_frame": 1e7
      }
    ],
    "body": {
      "product": "outer",
      "num": 1
    },
    "meta": {
      "distributed": false,
      "log_frequency": 10000,
      "eval_frequency": 10000,
      "rigorous_eval": 0,
      "max_session": 1,
      "max_trial": 1
    }
  },
}
